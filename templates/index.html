<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Voice Assistant</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 20px;
      background: #f4f4f4;
    }
    #container {
      max-width: 600px;
      margin: auto;
      background: white;
      padding: 20px;
      border-radius: 10px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }
    h1 {
      text-align: center;
    }
    #log {
      margin-top: 20px;
      padding: 10px;
      background: #f9f9f9;
      border-radius: 8px;
      max-height: 400px;
      overflow-y: auto;
    }
    .user {
      text-align: right;
      background: #dcf8c6;
      margin: 5px;
      padding: 10px;
      border-radius: 10px;
    }
    .assistant {
      text-align: left;
      background: #e6ecf0;
      margin: 5px;
      padding: 10px;
      border-radius: 10px;
    }
    #formSection {
      margin-top: 20px;
      display: none;
    }
    pre {
      background: #272822;
      color: #f8f8f2;
      padding: 10px;
      border-radius: 8px;
      overflow-x: auto;
    }
    button {
      padding: 10px 20px;
      margin-top: 10px;
      background-color: #00b894;
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
    }
    #statusLabel {
      font-weight: bold;
      text-align: center;
      margin-top: 10px;
    }
  </style>
</head>
<body>
  <div id="container">
    <h1>üéôÔ∏è Talk to Assistant</h1>
    <div id="log">Initializing assistant...</div>
    <div id="statusLabel"></div>
    <div id="formSection">
      <h3>üìù Live Form Data</h3>
      <pre id="formData"></pre>
      <button onclick="confirmAndGenerate()">‚úÖ Confirm & Generate PDF</button>
      <a id="downloadLink" href="/download" download style="display:none">üìÑ Download Filled PDF</a>
    </div>
    <audio id="replyAudio" controls style="display:none"></audio>
  </div>

  <script>
    let mediaRecorder;
    let audioChunks = [];
    let micStream;
    let vadInterval;
    let audioContext, analyser, sourceNode;
    let isRecording = false;
    let isAssistantSpeaking = false;

    async function requestMicAndStart() {
      try {
        micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        document.getElementById("log").innerHTML += `<div class='assistant'>üé§ Microphone access granted. Starting conversation...</div>`;
        startAssistantFlow();
      } catch (err) {
        document.getElementById("log").innerHTML += `<div class='assistant'>‚ùå Microphone access denied. Please enable it to continue.</div>`;
      }
    }

    async function startAssistantFlow() {
      await playInitialMessage();
    }

    async function playInitialMessage() {
      const res = await fetch("/initial-message");
      const data = await res.json();
      document.getElementById("log").innerHTML += `<div class='assistant'>ü§ñ ${data.assistant_text}</div>`;
      if (data.assistant_audio_base64) {
        isAssistantSpeaking = true;
        document.getElementById("statusLabel").textContent = "ü§ñ Assistant is speaking...";
        const audio = new Audio("data:audio/mp3;base64," + data.assistant_audio_base64);
        await audio.play().catch(() => {});
        audio.onended = () => {
          isAssistantSpeaking = false;
          document.getElementById("statusLabel").textContent = "üé§ You may speak now...";
          startVAD();
        };
      }
    }

    function startVAD() {
      audioContext = new AudioContext();
      analyser = audioContext.createAnalyser();
      sourceNode = audioContext.createMediaStreamSource(micStream);
      sourceNode.connect(analyser);
      analyser.fftSize = 512;

      mediaRecorder = new MediaRecorder(micStream);
      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstop = handleRecordingStop;

      vadInterval = setInterval(() => {
        const buffer = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(buffer);
        const volume = buffer.reduce((a, b) => a + b, 0) / buffer.length;

        if (volume > 10 && !isRecording) {
          audioChunks = [];
          mediaRecorder.start();
          isRecording = true;
          document.getElementById("statusLabel").textContent = "üé§ Listening...";
        }

        if (volume < 5 && isRecording) {
          mediaRecorder.stop();
          isRecording = false;
          document.getElementById("statusLabel").textContent = "‚è≥ Processing...";
        }
      }, 200);
    }

    async function handleRecordingStop() {
      clearInterval(vadInterval);

      const blob = new Blob(audioChunks, { type: 'audio/webm' });
      const formData = new FormData();
      formData.append("audio", blob, "recording.webm");

      try {
        const response = await fetch("/voice-stream", { method: "POST", body: formData });
        const result = await response.json();

        if (result.user_text) {
          document.getElementById("log").innerHTML += `<div class='user'>üë§ ${result.user_text}</div>`;
        }
        if (result.assistant_text) {
          document.getElementById("log").innerHTML += `<div class='assistant'>ü§ñ ${result.assistant_text}</div>`;
        }
        if (result.audio_base64) {
          isAssistantSpeaking = true;
          document.getElementById("statusLabel").textContent = "ü§ñ Assistant is speaking...";
          const audio = new Audio("data:audio/mp3;base64," + result.audio_base64);
          audio.play();
          audio.onended = () => {
            isAssistantSpeaking = false;
            document.getElementById("statusLabel").textContent = "üé§ You may speak now...";
            startVAD();
          };
        }
        if (result.form_data) {
          document.getElementById("formData").textContent = JSON.stringify(result.form_data, null, 2);
          document.getElementById("formSection").style.display = "block";
        }
      } catch (err) {
        document.getElementById("log").innerHTML += `<div class='assistant'>‚ùå Error processing voice input.</div>`;
      }
    }

    async function confirmAndGenerate() {
      const res = await fetch('/confirm', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ confirmed: true })
      });
      const result = await res.json();
      if (result.status === 'filled') {
        document.getElementById('downloadLink').style.display = 'inline-block';
      }
    }

    window.onload = () => {
      const startBtn = document.createElement("button");
      startBtn.textContent = "‚ñ∂Ô∏è Start Assistant";
      startBtn.style.marginTop = "10px";
      startBtn.onclick = () => {
        startBtn.remove();
        requestMicAndStart();
      };
      document.getElementById("container").appendChild(startBtn);
    };
  </script>
</body>
</html>
