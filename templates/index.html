<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Voice Assistant</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 20px;
      background: #f4f4f4;
    }
    #container {
      max-width: 600px;
      margin: auto;
      background: white;
      padding: 20px;
      border-radius: 10px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }
    h1 {
      text-align: center;
    }
    #log {
      margin-top: 20px;
      padding: 10px;
      background: #f9f9f9;
      border-radius: 8px;
      max-height: 400px;
      overflow-y: auto;
    }
    .user {
      text-align: right;
      background: #dcf8c6;
      margin: 5px;
      padding: 10px;
      border-radius: 10px;
    }
    .assistant {
      text-align: left;
      background: #e6ecf0;
      margin: 5px;
      padding: 10px;
      border-radius: 10px;
    }
    audio {
      display: block;
      margin: 20px auto 0;
    }
  </style>
</head>
<body>
  <div id="container">
    <h1>üéôÔ∏è Talk to Assistant</h1>
    <div id="log">Initializing assistant...</div>
    <audio id="replyAudio" controls></audio>
  </div>

  <script>
    let mediaRecorder;
    let audioChunks = [];

    async function requestMicAndStart() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        document.getElementById("log").innerHTML += `<div class='assistant'>üé§ Microphone access granted. Starting conversation...</div>`;
        startRecording(stream);
      } catch (err) {
        document.getElementById("log").innerHTML += `<div class='assistant'>‚ùå Microphone access denied. Please enable it to continue.</div>`;
      }
    }

    function startRecording(stream) {
      mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
      audioChunks = [];

      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);

      mediaRecorder.onstop = async () => {
        const blob = new Blob(audioChunks, { type: 'audio/webm' });
        const formData = new FormData();
        formData.append("audio", blob, "recording.webm");

        try {
          const response = await fetch("/voice-stream", {
            method: "POST",
            body: formData
          });
          const result = await response.json();

          if (result.user_text) {
            document.getElementById("log").innerHTML += `<div class='user'>üë§ ${result.user_text}</div>`;
          }
          if (result.assistant_text) {
            document.getElementById("log").innerHTML += `<div class='assistant'>ü§ñ ${result.assistant_text}</div>`;
          }
          if (result.audio_base64) {
            const audio = new Audio("data:audio/mp3;base64," + result.audio_base64);
            audio.play();
          }

          if (!result.end_conversation) {
            setTimeout(() => startRecording(stream), 1000);
          }
        } catch (err) {
          document.getElementById("log").innerHTML += `<div class='assistant'>‚ùå Error processing voice input.</div>`;
        }
      };

      mediaRecorder.start();
      setTimeout(() => mediaRecorder.stop(), 5000);
    }

    window.onload = async () => {
      const res = await fetch("/initial-message");
      const msg = await res.text();
      document.getElementById("log").innerHTML = `<div class='assistant'>ü§ñ ${msg}</div>`;

      const audioRes = await fetch("/initial-audio");
      const audioBase64 = await audioRes.text();
      const audio = new Audio("data:audio/mp3;base64," + audioBase64);
      audio.play();

      setTimeout(requestMicAndStart, 3000);
    };
  </script>
</body>
</html>
