<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Voice Assistant</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 20px;
      background: #f4f4f4;
    }
    #container {
      max-width: 600px;
      margin: auto;
      background: white;
      padding: 20px;
      border-radius: 10px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }
    h1 {
      text-align: center;
    }
    #log {
      margin-top: 20px;
      padding: 10px;
      background: #f9f9f9;
      border-radius: 8px;
      max-height: 400px;
      overflow-y: auto;
    }
    .user {
      text-align: right;
      background: #dcf8c6;
      margin: 5px;
      padding: 10px;
      border-radius: 10px;
    }
    .assistant {
      text-align: left;
      background: #e6ecf0;
      margin: 5px;
      padding: 10px;
      border-radius: 10px;
    }
    #formSection {
      margin-top: 20px;
      display: none;
    }
    #editableForm input {
      width: 100%;
      margin-bottom: 8px;
      padding: 6px;
      border: 1px solid #ccc;
      border-radius: 4px;
    }
    button {
      padding: 10px 20px;
      margin-top: 10px;
      background-color: #00b894;
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
    }
    #statusLabel {
      font-weight: bold;
      text-align: center;
      margin-top: 10px;
    }
  </style>
</head>
<body>
  <div id="container">
    <h1>üéôÔ∏è Talk to Assistant</h1>
    <div id="log">Initializing assistant...</div>
    <div id="statusLabel"></div>

    <div id="formSection">
      <h3>üìù Review & Edit Form Data</h3>
      <form id="editableForm"></form>
      <button id="confirmBtn" onclick="confirmAndGenerate()" disabled>‚úÖ Confirm & Generate PDF</button>
      <a id="downloadLink" href="/download" download style="display:none">üìÑ Download Filled PDF</a>
      <button id="resetBtn" onclick="resetConversation()" style="display:none; background-color: #636e72;">üîÅ Start Over</button>
    </div>

    <audio id="replyAudio" controls style="display:none"></audio>
  </div>

  <script>
    let mediaRecorder, audioChunks = [], micStream, vadInterval;
    let audioContext, analyser, sourceNode;
    let isRecording = false, isAssistantSpeaking = false, isConversationEnded = false;
    let latestFormData = {};

    async function requestMicAndStart() {
      try {
        micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        document.getElementById("log").innerHTML += `<div class='assistant'>üé§ Microphone access granted. Starting conversation...</div>`;
        startAssistantFlow();
      } catch (err) {
        document.getElementById("log").innerHTML += `<div class='assistant'>‚ùå Microphone access denied. Please enable it to continue.</div>`;
      }
    }

    async function startAssistantFlow() {
      await playInitialMessage();
    }

    async function playInitialMessage() {
      const res = await fetch("/initial-message");
      const data = await res.json();
      document.getElementById("log").innerHTML += `<div class='assistant'>ü§ñ ${data.assistant_text}</div>`;
      if (data.assistant_audio_base64) {
        isAssistantSpeaking = true;
        document.getElementById("statusLabel").textContent = "ü§ñ Assistant is speaking...";
        const audio = new Audio("data:audio/mp3;base64," + data.assistant_audio_base64);
        audio.play().catch(() => {
          document.body.addEventListener("click", () => audio.play(), { once: true });
        });
        audio.onended = () => {
          isAssistantSpeaking = false;
          document.getElementById("statusLabel").textContent = "üé§ You may speak now...";
          startVAD();
        };
      }
    }

    function startVAD() {
      audioContext = new AudioContext();
      analyser = audioContext.createAnalyser();
      sourceNode = audioContext.createMediaStreamSource(micStream);
      sourceNode.connect(analyser);
      analyser.fftSize = 512;

      mediaRecorder = new MediaRecorder(micStream);
      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstop = handleRecordingStop;

      vadInterval = setInterval(() => {
        const buffer = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(buffer);
        const volume = buffer.reduce((a, b) => a + b, 0) / buffer.length;

        if (volume > 10 && !isRecording) {
          audioChunks = [];
          mediaRecorder.start();
          isRecording = true;
          document.getElementById("statusLabel").textContent = "üé§ Listening...";
        }

        if (volume < 5 && isRecording) {
          mediaRecorder.stop();
          isRecording = false;
          document.getElementById("statusLabel").textContent = "‚è≥ Processing...";
        }
      }, 200);
    }

    async function handleRecordingStop() {
      clearInterval(vadInterval);
      const blob = new Blob(audioChunks, { type: 'audio/webm' });
      const formData = new FormData();
      formData.append("audio", blob, "recording.webm");

      try {
        const response = await fetch("/voice-stream", { method: "POST", body: formData });
        const result = await response.json();

        if (result.user_text)
          document.getElementById("log").innerHTML += `<div class='user'>üë§ ${result.user_text}</div>`;
        if (result.assistant_text) {
          document.getElementById("log").innerHTML += `<div class='assistant'>ü§ñ ${result.assistant_text}</div>`;
          if (result.assistant_text.includes("END OF CONVERSATION")) {
            isConversationEnded = true;
            document.getElementById("confirmBtn").disabled = false;
          }
        }
        if (result.audio_base64) {
          isAssistantSpeaking = true;
          document.getElementById("statusLabel").textContent = "ü§ñ Assistant is speaking...";
          const audio = new Audio("data:audio/mp3;base64," + result.audio_base64);
          audio.play();
          audio.onended = () => {
            isAssistantSpeaking = false;
            document.getElementById("statusLabel").textContent = isConversationEnded ? "‚úÖ Ready to confirm." : "üé§ You may speak now...";
            if (!isConversationEnded) startVAD();
            else document.getElementById("resetBtn").style.display = "inline-block";
          };
        }
        if (result.form_data) {
          latestFormData = result.form_data;
          updateEditableForm(result.form_data);
          document.getElementById("formSection").style.display = "block";
        }
      } catch (err) {
        document.getElementById("log").innerHTML += `<div class='assistant'>‚ùå Error processing voice input.</div>`;
      }
    }

    function updateEditableForm(data) {
      const form = document.getElementById("editableForm");
      form.innerHTML = "";
      for (const key in data) {
        const label = document.createElement("label");
        label.textContent = key;
        const input = document.createElement("input");
        input.name = key;
        input.value = data[key] || "";
        form.appendChild(label);
        form.appendChild(input);
      }
    }

    async function confirmAndGenerate() {
      const formElements = document.getElementById("editableForm").elements;
      const updatedForm = {};
      for (let i = 0; i < formElements.length; i++) {
        if (formElements[i].name) {
          updatedForm[formElements[i].name] = formElements[i].value;
        }
      }

      const res = await fetch('/confirm', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ confirmed: true, form_data: updatedForm })
      });

      const result = await res.json();
      if (result.status === 'filled') {
        document.getElementById('downloadLink').style.display = 'inline-block';
      } else {
        alert("‚ùå Cannot generate PDF. Make sure the assistant completed the conversation.");
      }
    }

    function resetConversation() {
      isConversationEnded = false;
      isRecording = false;
      isAssistantSpeaking = false;
      audioChunks = [];
      document.getElementById("log").innerHTML = "Initializing assistant...";
      document.getElementById("statusLabel").textContent = "";
      document.getElementById("formSection").style.display = "none";
      document.getElementById("editableForm").innerHTML = "";
      document.getElementById("downloadLink").style.display = "none";
      document.getElementById("resetBtn").style.display = "none";
      document.getElementById("confirmBtn").disabled = true;
      startAssistantFlow();
    }

    window.onload = () => {
      const startBtn = document.createElement("button");
      startBtn.textContent = "‚ñ∂Ô∏è Start Assistant";
      startBtn.style.marginTop = "10px";
      startBtn.onclick = () => {
        startBtn.remove();
        requestMicAndStart();
      };
      document.getElementById("container").appendChild(startBtn);
    };
  </script>
</body>
</html>
