<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Voice Assistant</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 20px;
      background: #f4f4f4;
    }
    #container {
      max-width: 700px;
      margin: auto;
      background: white;
      padding: 20px;
      border-radius: 10px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }
    h1 {
      text-align: center;
    }
    #log {
      margin-top: 20px;
      padding: 10px;
      background: #f9f9f9;
      border-radius: 8px;
      max-height: 400px;
      overflow-y: auto;
    }
    .user {
      text-align: right;
      background: #dcf8c6;
      margin: 5px;
      padding: 10px;
      border-radius: 10px;
    }
    .assistant {
      text-align: left;
      background: #e6ecf0;
      margin: 5px;
      padding: 10px;
      border-radius: 10px;
    }
    #formSection {
      margin-top: 20px;
      display: none;
    }
    label {
      font-weight: bold;
      display: block;
      margin-top: 10px;
    }
    input {
      width: 100%;
      padding: 8px;
      margin-top: 4px;
      box-sizing: border-box;
    }
    button {
      padding: 10px 20px;
      margin-top: 20px;
      background-color: #00b894;
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
    }
    #statusLabel {
      font-weight: bold;
      text-align: center;
      margin-top: 10px;
    }
  </style>
</head>
<body>
  <div id="container">
    <h1>üéôÔ∏è Talk to Assistant</h1>
    <div id="log">Initializing assistant...</div>
    <div id="statusLabel"></div>

    <div id="formSection">
      <h3>üìù Confirm Form Data</h3>
      <form id="formEditor">
        <!-- Fields will be inserted dynamically -->
      </form>
      <button onclick="confirmAndGenerate()">‚úÖ Confirm & Generate PDF</button>
      <a id="downloadLink" href="/download" download style="display:none; margin-left: 10px;">üìÑ Download Filled PDF</a>
      <button id="resetBtn" onclick="resetConversation()" style="display:none; background-color: #636e72; margin-left: 10px;">üîÅ Start Over</button>
    </div>
    <audio id="replyAudio" controls style="display:none"></audio>
  </div>

  <script>
    let micStream, mediaRecorder, vadInterval;
    let audioChunks = [], audioContext, analyser, sourceNode;
    let isRecording = false, isAssistantSpeaking = false, isConversationEnded = false;

    async function requestMicAndStart() {
      try {
        micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        document.getElementById("log").innerHTML += `<div class='assistant'>üé§ Microphone access granted. Starting conversation...</div>`;
        startAssistantFlow();
      } catch {
        document.getElementById("log").innerHTML += `<div class='assistant'>‚ùå Microphone access denied. Please enable it to continue.</div>`;
      }
    }

    async function startAssistantFlow() {
      const res = await fetch("/initial-message");
      const data = await res.json();
      document.getElementById("log").innerHTML += `<div class='assistant'>ü§ñ ${data.assistant_text}</div>`;
      if (data.assistant_audio_base64) {
        isAssistantSpeaking = true;
        document.getElementById("statusLabel").textContent = "ü§ñ Assistant is speaking...";
        const audio = new Audio("data:audio/mp3;base64," + data.assistant_audio_base64);
        audio.play().catch(() => {
          document.getElementById("log").innerHTML += `<div class='assistant'>üîà Tap to hear assistant reply.</div>`;
          document.body.addEventListener("click", () => audio.play(), { once: true });
        });
        audio.onended = () => {
          isAssistantSpeaking = false;
          document.getElementById("statusLabel").textContent = "üé§ You may speak now...";
          startVAD();
        };
      }
    }

    function startVAD() {
      audioContext = new AudioContext();
      analyser = audioContext.createAnalyser();
      sourceNode = audioContext.createMediaStreamSource(micStream);
      sourceNode.connect(analyser);
      analyser.fftSize = 512;

      mediaRecorder = new MediaRecorder(micStream);
      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstop = handleRecordingStop;

      vadInterval = setInterval(() => {
        const buffer = new Uint8Array(analyser.frequencyBinCount);
        analyser.getByteFrequencyData(buffer);
        const volume = buffer.reduce((a, b) => a + b, 0) / buffer.length;

        if (volume > 10 && !isRecording) {
          audioChunks = [];
          mediaRecorder.start();
          isRecording = true;
          document.getElementById("statusLabel").textContent = "üé§ Listening...";
        }
        if (volume < 5 && isRecording) {
          mediaRecorder.stop();
          isRecording = false;
          document.getElementById("statusLabel").textContent = "‚è≥ Processing...";
        }
      }, 200);
    }

    async function handleRecordingStop() {
      clearInterval(vadInterval);
      const blob = new Blob(audioChunks, { type: 'audio/webm' });
      const formData = new FormData();
      formData.append("audio", blob, "recording.webm");

      try {
        const res = await fetch("/voice-stream", { method: "POST", body: formData });
        const result = await res.json();

        if (result.user_text) document.getElementById("log").innerHTML += `<div class='user'>üë§ ${result.user_text}</div>`;
        if (result.assistant_text) {
          document.getElementById("log").innerHTML += `<div class='assistant'>ü§ñ ${result.assistant_text}</div>`;
          if (result.assistant_text.includes("END OF CONVERSATION")) isConversationEnded = true;
        }

        if (result.audio_base64) {
          isAssistantSpeaking = true;
          document.getElementById("statusLabel").textContent = "ü§ñ Assistant is speaking...";
          const audio = new Audio("data:audio/mp3;base64," + result.audio_base64);
          audio.play().catch(() => {
            document.body.addEventListener("click", () => audio.play(), { once: true });
          });
          audio.onended = () => {
            isAssistantSpeaking = false;
            if (!isConversationEnded) {
              document.getElementById("statusLabel").textContent = "üé§ You may speak now...";
              startVAD();
            } else {
              document.getElementById("statusLabel").textContent = "‚úÖ Thank you! The form is complete.";
              document.getElementById("resetBtn").style.display = "inline-block";
            }
          };
        }

        if (result.form_data) {
          document.getElementById("formSection").style.display = "block";
          populateEditableForm(result.form_data);
        }
      } catch (err) {
        document.getElementById("log").innerHTML += `<div class='assistant'>‚ùå Error processing voice input.</div>`;
      }
    }

    function populateEditableForm(data) {
      const formEditor = document.getElementById("formEditor");
      formEditor.innerHTML = "";
      for (const key in data) {
        const label = document.createElement("label");
        label.textContent = key;
        const input = document.createElement("input");
        input.name = key;
        input.value = data[key] || "";
        formEditor.appendChild(label);
        formEditor.appendChild(input);
      }
    }

    async function confirmAndGenerate() {
      if (!isConversationEnded) {
        alert("‚ùå Cannot generate PDF. Make sure the assistant completed the conversation.");
        return;
      }

      const form = document.getElementById("formEditor");
      const editedData = {};
      for (const field of form.elements) {
        if (field.name) editedData[field.name] = field.value;
      }

      const res = await fetch('/confirm', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ confirmed: true, form_data: editedData })
      });

      const result = await res.json();
      if (result.status === 'filled') {
        document.getElementById('downloadLink').style.display = 'inline-block';
      } else {
        alert("‚ùå PDF generation failed.");
      }
    }

    function resetConversation() {
      isConversationEnded = false;
      isRecording = false;
      isAssistantSpeaking = false;
      audioChunks = [];
      document.getElementById("log").innerHTML = "Initializing assistant...";
      document.getElementById("statusLabel").textContent = "";
      document.getElementById("formSection").style.display = "none";
      document.getElementById("formEditor").innerHTML = "";
      document.getElementById("downloadLink").style.display = "none";
      document.getElementById("resetBtn").style.display = "none";
      fetch("/reset", { method: "POST" });
      startAssistantFlow();
    }

    window.onload = () => {
      const startBtn = document.createElement("button");
      startBtn.textContent = "‚ñ∂Ô∏è Start Assistant";
      startBtn.style.marginTop = "10px";
      startBtn.onclick = () => {
        startBtn.remove();
        requestMicAndStart();
      };
      document.getElementById("container").appendChild(startBtn);
    };
  </script>
</body>
</html>
